
[2025-08-17 07:51:27]
‚úÖ requests already installed.
----------------------------------------

[2025-08-17 07:51:27]
üì¶ Installing beautifulsoup4 ...
----------------------------------------

[2025-08-17 07:51:28]
üìú Executing Code:
import requests
from bs4 import BeautifulSoup

url = "https://en.wikipedia.org/wiki/List_of_highest-grossing_films"
response = requests.get(url)

if response.status_code == 200:
    soup = BeautifulSoup(response.content, "html.parser")

    summary = "URL: " + url + "\n\n"
    summary += "Headings found:\n"
    for heading in soup.find_all(["h1", "h2", "h3"])[
        :5
    ]:  # Limiting to first 5 headings for brevity
        summary += f"- {heading.get_text(strip=True)}\n"

    summary += "\nTables found:\n"
    tables = soup.find_all("table", {"class": "wikitable"})
    for i, table in enumerate(tables[:2]):  # Limiting to first 2 tables for brevity
        headers = [th.get_text(strip=True) for th in table.find_all("th")]
        summary += (
            f"Table {i+1} headers: {headers[:5]}\n"  # Limiting to first 5 headers
        )

    with open("uploads/02a3c161-c5a8-4c56-9832-6e2af5ce108e/metadata.txt", "a") as f:
        f.write(summary)
    print("Successfully scraped basic info and saved to metadata.txt")
else:
    print(f"Failed to fetch URL. Status code: {response.status_code}")

----------------------------------------

[2025-08-17 07:51:30]
‚úÖ Code executed successfully:
Successfully scraped basic info and saved to metadata.txt

----------------------------------------

[2025-08-17 07:51:38]
‚úÖ pandas already installed.
----------------------------------------

[2025-08-17 07:51:38]
‚úÖ requests already installed.
----------------------------------------

[2025-08-17 07:51:38]
üì¶ Installing lxml ...
----------------------------------------

[2025-08-17 07:51:40]
üìú Executing Code:
import pandas as pd
import requests

url = "https://en.wikipedia.org/wiki/List_of_highest-grossing_films"

try:
    tables = pd.read_html(requests.get(url).text, attrs={"class": "wikitable"})
    df = tables[0]
    output_path = (
        "uploads/02a3c161-c5a8-4c56-9832-6e2af5ce108e/highest_grossing_films.csv"
    )
    df.to_csv(output_path, index=False)

    metadata_update = (
        f"\nSuccessfully downloaded and saved the table to {output_path}\n"
    )
    with open("uploads/02a3c161-c5a8-4c56-9832-6e2af5ce108e/metadata.txt", "a") as f:
        f.write(metadata_update)
    print(f"Successfully saved data to {output_path}")
except Exception as e:
    print(f"An error occurred: {e}")

----------------------------------------

[2025-08-17 07:51:41]
‚úÖ Code executed successfully:
Successfully saved data to uploads/02a3c161-c5a8-4c56-9832-6e2af5ce108e/highest_grossing_films.csv

----------------------------------------

[2025-08-17 07:52:12]
‚úÖ pandas already installed.
----------------------------------------

[2025-08-17 07:52:12]
‚úÖ numpy already installed.
----------------------------------------

[2025-08-17 07:52:12]
‚úÖ matplotlib already installed.
----------------------------------------

[2025-08-17 07:52:12]
üì¶ Installing seaborn ...
----------------------------------------

[2025-08-17 07:52:13]
üìú Executing Code:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import io
import base64
import json
import re


def solve_and_save():
    try:
        # Load the data
        file_path = (
            "uploads/02a3c161-c5a8-4c56-9832-6e2af5ce108e/highest_grossing_films.csv"
        )
        df = pd.read_csv(file_path)

        # --- Data Cleaning ---
        def clean_currency(value):
            if isinstance(value, str):
                value = re.sub(r"\[\d+\]", "", value)  # Remove citations like [1]
                value = value.replace("$", "").replace(",", "")
            try:
                return float(value)
            except (ValueError, TypeError):
                return np.nan

        df["Worldwide gross"] = df["Worldwide gross"].apply(clean_currency)
        df["Year"] = pd.to_numeric(df["Year"], errors="coerce")
        df["Rank"] = pd.to_numeric(df["Rank"], errors="coerce")
        df["Peak"] = pd.to_numeric(df["Peak"], errors="coerce")
        df.dropna(subset=["Worldwide gross", "Year", "Rank", "Peak"], inplace=True)
        df["Year"] = df["Year"].astype(int)

        # --- Question 1: How many $2 bn movies were released before 2000? ---
        movies_2bn_before_2000 = df[
            (df["Worldwide gross"] >= 2_000_000_000) & (df["Year"] < 2000)
        ]
        answer1 = len(movies_2bn_before_2000)

        # --- Question 2: Which is the earliest film that grossed over $1.5 bn? ---
        movies_1_5bn = df[df["Worldwide gross"] >= 1_500_000_000]
        earliest_film = movies_1_5bn.sort_values(by="Year").iloc[0]
        answer2 = earliest_film["Title"]

        # --- Question 3: What's the correlation between the Rank and Peak? ---
        correlation = df["Rank"].corr(df["Peak"])
        answer3 = correlation

        # --- Question 4: Draw a scatterplot of Rank and Peak ---
        plt.figure(figsize=(10, 6))
        sns.regplot(
            x="Rank", y="Peak", data=df, line_kws={"color": "red", "linestyle": "--"}
        )
        plt.title("Rank vs. Peak of Highest-Grossing Films")
        plt.xlabel("Rank")
        plt.ylabel("Peak")

        buf = io.BytesIO()
        plt.savefig(buf, format="png", bbox_inches="tight")
        buf.seek(0)
        image_base64 = base64.b64encode(buf.read()).decode("utf-8")
        answer4 = f"data:image/png;base64,{image_base64}"
        buf.close()
        plt.close()

        # --- Consolidate and Save Results ---
        results = [answer1, answer2, answer3, answer4]
        with open("uploads/02a3c161-c5a8-4c56-9832-6e2af5ce108e/result.json", "w") as f:
            json.dump(results, f)

        with open(
            "uploads/02a3c161-c5a8-4c56-9832-6e2af5ce108e/metadata.txt", "a"
        ) as f:
            f.write("\nFinal answers generated and saved to result.json.")

        print("Successfully processed data and saved the final answers.")

    except Exception as e:
        print(f"An error occurred: {e}")


solve_and_save()

----------------------------------------

[2025-08-17 07:52:13]
‚úÖ Code executed successfully:
An error occurred: 'Worldwide gross'

----------------------------------------

[2025-08-17 07:52:29]
‚úÖ pandas already installed.
----------------------------------------

[2025-08-17 07:52:29]
‚úÖ numpy already installed.
----------------------------------------

[2025-08-17 07:52:29]
‚úÖ matplotlib already installed.
----------------------------------------

[2025-08-17 07:52:29]
‚úÖ seaborn already installed.
----------------------------------------

[2025-08-17 07:52:29]
üìú Executing Code:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import io
import base64
import json
import re


def solve_and_save():
    # Load the data
    file_path = (
        "uploads/02a3c161-c5a8-4c56-9832-6e2af5ce108e/highest_grossing_films.csv"
    )
    df = pd.read_csv(file_path)

    # --- Data Cleaning ---
    def clean_currency(value):
        if isinstance(value, str):
            value = re.sub(r"\[\d+\]", "", value)  # Remove citations like [1]
            value = value.replace("$", "").replace(",", "")
        try:
            return float(value)
        except (ValueError, TypeError):
            return np.nan

    df["Worldwide gross"] = df["Worldwide gross"].apply(clean_currency)
    df["Year"] = pd.to_numeric(df["Year"], errors="coerce")
    df["Rank"] = pd.to_numeric(df["Rank"], errors="coerce")
    df["Peak"] = pd.to_numeric(df["Peak"], errors="coerce")
    df.dropna(subset=["Worldwide gross", "Year", "Rank", "Peak"], inplace=True)
    df["Year"] = df["Year"].astype(int)

    # --- Question 1: How many $2 bn movies were released before 2000? ---
    movies_2bn_before_2000 = df[
        (df["Worldwide gross"] >= 2_000_000_000) & (df["Year"] < 2000)
    ]
    answer1 = len(movies_2bn_before_2000)

    # --- Question 2: Which is the earliest film that grossed over $1.5 bn? ---
    movies_1_5bn = df[df["Worldwide gross"] >= 1_500_000_000]
    earliest_film = movies_1_5bn.sort_values(by="Year").iloc[0]
    answer2 = earliest_film["Title"]

    # --- Question 3: What's the correlation between the Rank and Peak? ---
    correlation = df["Rank"].corr(df["Peak"])
    answer3 = correlation

    # --- Question 4: Draw a scatterplot of Rank and Peak ---
    plt.figure(figsize=(10, 6))
    sns.regplot(
        x="Rank", y="Peak", data=df, line_kws={"color": "red", "linestyle": "--"}
    )
    plt.title("Rank vs. Peak of Highest-Grossing Films")
    plt.xlabel("Rank")
    plt.ylabel("Peak")

    buf = io.BytesIO()
    plt.savefig(buf, format="png", bbox_inches="tight")
    buf.seek(0)
    image_base64 = base64.b64encode(buf.read()).decode("utf-8")
    answer4 = f"data:image/png;base64,{image_base64}"
    buf.close()
    plt.close()

    # --- Consolidate and Save Results ---
    results = [answer1, answer2, answer3, answer4]
    with open("uploads/02a3c161-c5a8-4c56-9832-6e2af5ce108e/result.json", "w") as f:
        json.dump(results, f)


solve_and_save()

----------------------------------------

[2025-08-17 07:52:29]
‚ùå Execution error:
Traceback (most recent call last):
  File "/home/kas4453/kas/tds-project-2/venv/lib/python3.13/site-packages/pandas/core/indexes/base.py", line 3812, in get_loc
    return self._engine.get_loc(casted_key)
           ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^
  File "pandas/_libs/index.pyx", line 167, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/index.pyx", line 196, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 7096, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'Worldwide gross'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/kas4453/kas/tds-project-2/uploads/02a3c161-c5a8-4c56-9832-6e2af5ce108e/job_/script.py", line 65, in <module>
    solve_and_save()
    ~~~~~~~~~~~~~~^^
  File "/home/kas4453/kas/tds-project-2/uploads/02a3c161-c5a8-4c56-9832-6e2af5ce108e/job_/script.py", line 25, in solve_and_save
    df['Worldwide gross'] = df['Worldwide gross'].apply(clean_currency)
                            ~~^^^^^^^^^^^^^^^^^^^
  File "/home/kas4453/kas/tds-project-2/venv/lib/python3.13/site-packages/pandas/core/frame.py", line 4107, in __getitem__
    indexer = self.columns.get_loc(key)
  File "/home/kas4453/kas/tds-project-2/venv/lib/python3.13/site-packages/pandas/core/indexes/base.py", line 3819, in get_loc
    raise KeyError(key) from err
KeyError: 'Worldwide gross'

----------------------------------------
